# ü§ñ Estimateur IA ‚Äî Documentation technique

## Concept

L'estimateur calcule le temps d'attente pour une commande en tenant compte de plusieurs facteurs dynamiques. C'est une IA simple bas√©e sur des r√®gles et des statistiques.

## Algorithme

### Formule g√©n√©rale

```
Temps_estim√© = (Temps_base √ó Facteur_backlog √ó Facteur_service) √∑ Postes_parall√®les
```

Avec un minimum garanti de **120 secondes** (2 minutes).

### 1. Temps de base

Somme pond√©r√©e par quantit√© :

```javascript
temps_base = Œ£ (plat.avg_prep_seconds √ó quantit√©)
```

Exemple :
- Ramen (540s) √ó 1 = 540s
- Sushi (420s) √ó 2 = 840s
- **Total : 1380s (23 min)**

### 2. Facteur backlog

Plus il y a de commandes en attente, plus le temps augmente :

```javascript
commandes_devant = COUNT(orders WHERE id < current_order AND status IN ('VALIDATED','PREPARING','READY'))
facteur = 1 + min(0.05 √ó commandes_devant, 2.0)
```

- **+5% par commande** devant
- **Maximum +200%** (facteur 3.0)

Exemples :
- 0 commandes ‚Üí √ó1.0
- 3 commandes ‚Üí √ó1.15 (+15%)
- 10 commandes ‚Üí √ó1.5 (+50%)
- 40+ commandes ‚Üí √ó3.0 (+200%, plafond)

### 3. Facteur service (heures de pointe)

P√©riode de rush = pr√©parations plus lentes :

```javascript
heure = date.getHours()
if ((12 ‚â§ heure < 14) || (19 ‚â§ heure < 22)) {
  facteur = 1.2  // +20%
} else {
  facteur = 1.0
}
```

### 4. Parall√©lisation cuisine

Hypoth√®se : **2 postes de cuisine** travaillent simultan√©ment.

```javascript
temps_final = temps_estim√© √∑ 2
```

Cela r√©duit de moiti√© le temps th√©orique.

## Exemple complet

**Commande :** Ramen (540s) + Donburi (420s) √† 13h00

**Calcul :**
1. Temps base : 540 + 420 = **960s**
2. Backlog : 5 commandes devant ‚Üí √ó1.25
   - 960 √ó 1.25 = **1200s**
3. Service (13h = rush) ‚Üí √ó1.2
   - 1200 √ó 1.2 = **1440s**
4. Parall√©lisation √∑ 2
   - 1440 √∑ 2 = **720s**
5. **R√©sultat : 12 minutes**

## Am√©lioration future (ML)

Pour passer √† un vrai ML :

### Donn√©es √† collecter

```sql
CREATE TABLE prep_history (
  order_id INT,
  plat_id INT,
  quantite INT,
  heure_validation TIMESTAMP,
  heure_pret TIMESTAMP,
  duree_reelle_seconds INT,
  jour_semaine ENUM('lundi','mardi',...),
  service ENUM('midi','soir','hors_service')
);
```

### Mod√®le de r√©gression

**Features (X) :**
- `nombre_plats` (quantit√© totale)
- `complexite_moyenne` (avg_prep_seconds moyen)
- `commandes_en_cours`
- `heure` (0-23)
- `jour_semaine` (encod√© one-hot)
- `service` (midi/soir/autre)

**Target (y) :**
- `duree_reelle_seconds`

**Algorithme :** Random Forest Regressor ou Gradient Boosting

```python
from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(n_estimators=100)
model.fit(X_train, y_train)

# Pr√©diction
temps_estime = model.predict([[nb_plats, complexite, backlog, heure, ...]])
```

### Entra√Ænement continu

Chaque commande servie alimente le mod√®le :

```javascript
// Apr√®s markServed()
const dureeReelle = (served_at - validated_at) / 1000;
await pool.query('INSERT INTO prep_history (...) VALUES (...)', [orderId, dureeReelle, ...]);

// R√©entra√Æner le mod√®le chaque nuit (cron job)
```

## M√©triques de qualit√©

Pour √©valuer l'estimateur :

```sql
SELECT 
  AVG(ABS(estimated_wait_seconds - actual_duration)) AS mae,
  SQRT(AVG(POW(estimated_wait_seconds - actual_duration, 2))) AS rmse
FROM (
  SELECT 
    estimated_wait_seconds,
    TIMESTAMPDIFF(SECOND, validated_at, served_at) AS actual_duration
  FROM orders
  WHERE status = 'SERVED' AND validated_at IS NOT NULL
) AS stats;
```

- **MAE** (Mean Absolute Error) : √©cart moyen en secondes
- **RMSE** (Root Mean Square Error) : p√©nalise les gros √©carts

**Objectif :** MAE < 120s (¬±2 minutes)

## Int√©gration Python ML (optionnel)

### Backend hybride

```javascript
// routes/orders.js
import { exec } from 'child_process';

async function estimateWithML(orderId) {
  return new Promise((resolve) => {
    exec(`python ml/predict.py ${orderId}`, (err, stdout) => {
      if (err) return resolve(estimateWaitSecondsForOrder(orderId)); // fallback
      resolve(parseInt(stdout.trim()));
    });
  });
}
```

### Script Python

```python
# ml/predict.py
import sys
import joblib
import mysql.connector

order_id = int(sys.argv[1])
model = joblib.load('ml/model.pkl')

# Charger features depuis MySQL
conn = mysql.connector.connect(host='localhost', user='root', database='glescrocs')
cursor = conn.cursor()
cursor.execute("SELECT ... FROM orders WHERE id=%s", (order_id,))
features = cursor.fetchone()

# Pr√©diction
prediction = model.predict([features])[0]
print(int(prediction))
```

## Configuration dynamique

Permettre d'ajuster les facteurs :

```sql
CREATE TABLE estimator_config (
  key VARCHAR(50) PRIMARY KEY,
  value FLOAT
);

INSERT INTO estimator_config VALUES
  ('backlog_increment', 0.05),
  ('backlog_max', 2.0),
  ('service_rush_factor', 1.2),
  ('parallel_posts', 2);
```

Charger au d√©marrage :

```javascript
const config = await pool.query('SELECT key, value FROM estimator_config');
const settings = Object.fromEntries(config[0].map(r => [r.key, r.value]));
```

## Conclusion

L'estimateur actuel est **simple mais efficace** pour un MVP. Pour aller plus loin :
1. Collecter des donn√©es r√©elles pendant 2-4 semaines
2. Entra√Æner un mod√®le ML (Random Forest)
3. A/B tester vs algorithme actuel
4. D√©ployer le meilleur mod√®le
